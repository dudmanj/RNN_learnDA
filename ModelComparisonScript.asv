
load ~/'Dropbox (HHMI)'/matlab.mat

%% LearnDA simulations scripts for comparing Cntrl (various inits) w/ StimLick+ StimLick- Stim+Lick+
global pt_on;
pt_on = 1;

% Code to run simulation and display key output measures:

% stim_list = [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 ];
% % inits = repmat(ii([141 159 166 176 191 150]),1,6);
% inits = repmat(ii([141  96 100 110 104  55]),1,6);
% inits = repmat(ii([141 159 166 176 191 150]),1,6);

stim_list = [-1*ones(1,18) zeros(1,18) ones(1,18) 20*ones(1,18)];
inits = repmat(ii([141 191 178 110 166 130]),1,12);
wIn_vec = repmat([zeros(1,6) zeros(1,6) ones(1,6)*0.33],1,4);
tau_vec = repmat([ones(1,6) 1+rand(1,6) ones(1,6)],1,4);
clear run;

parfor g = 1:numel(stim_list)

    net_init = gens.dets(inits(g)).net % diverse initial states
                
%     net_init.wIn(net.oUind,:) = [0 0];
    net_init.wIn(net.oUind,:) = [0 wIn_vec(g)];
    tau_trans = tau_vec(g); % now controls eta_wIn learning rate
    filt_scale = 50; % plant scale factor currently

    % stim scalar determines whether a control (0) or lick- (-1) or lick+ (1) perturbation experiments
    stim = stim_list(g);
    [output,net_out,pred_da_sense,pred_da_move,pred_da_move_u,pred_da_sense_u,pred_da_move_o,pred_da_sense_o] = dlRNN_train_learnDA(net_init,input,input_omit,input_uncued,target,act_func_handle,learn_func_handle,transfer_func_handle,65,tau_trans,stim,filt_scale);

    run(g).output = output;
    run(g).net = net_out;
    run(g).pred_da_sense = pred_da_sense;
    run(g).pred_da_move = pred_da_move;
    run(g).pred_da_sense_u = pred_da_sense_u;
    run(g).pred_da_move_u = pred_da_move_u;
    run(g).pred_da_sense_o = pred_da_sense_o;
    run(g).pred_da_move_o = pred_da_move_o;
    disp(['Completed run: ' num2str(g)]);

end

% save ~/'Dropbox (HHMI)'/run run stim_list inits

%% LAST BITS NEEDED FOR PAPER FIGURES
% 1. Plot Cost vs Ant vs React for all Cntrl model sims X
% 2. Cued-DA stim DA and licking predictions X
% 3. RPE predictions
% 4. Lick+ / Lick- predictions
% 5. PE|lick+ and PE|lick- vs training trials X
% 6. DA and Licking predictions for stimLick-, stimLick+, Stim++Lick+

%% 0. Need to compute a function that converts policy into a "transient" variable equivalent to experimental data

trans_vec = 0:0.5:11;
lat_vec = zeros(size(trans_vec))
reps=1:1000;
lat = zeros(size(reps));
activity = zeros(1,3000);

for j=1:numel(trans_vec)
    activity(1600:1610) = trans_vec(j);
    for i=reps
        [checks,state] = dlRNN_Pcheck_transfer(activity,50);
        tmp = checks(checks>1600);
        if numel(tmp>0)
            lat(i) = tmp(1)-1600;
        else
            lat(i) = 1400;
        end
    end
    lat_vec(j) = mean(lat);
end        

figure(10); clf;
plot(trans_vec,lat_vec);
rct_off = lat_vec(end);
react_model = fit( trans_vec' , lat_vec'-rct_off,'exp1');    
react_sm = react_model(trans_vec)+rct_off;
hold on; plot(trans_vec,react_sm);

%% 0.5 Compute full error surface
s_map = TNC_CreateRBColormap(1000,'cpb');
trans_vec = -0.5:0.5:11;
sust_vec = -0.35:0.05:1;
reps=1:100;
lat = zeros(numel(sust_vec),numel(reps));
lat_mat = zeros(numel(sust_vec),numel(trans_vec));
cost_mat = zeros(numel(sust_vec),numel(trans_vec));

for ss=1:numel(sust_vec)
    for tt=1:numel(trans_vec)

        activity = [zeros(1,600) ones(1,950).*sust_vec(ss) zeros(1,1450)];
        activity(1600:1610) = trans_vec(tt);

        for i=reps
            [checks,state] = dlRNN_Pcheck_transfer(activity,50);
            tmp = checks(checks>1600);
            if numel(tmp)>0
                lat(ss,i) = tmp(1)-1600;
            else
                lat(ss,i) = 1400;
            end
        end
        lat_mat(ss,tt) = mean(lat(ss,:));
        cost_mat(ss,tt) = 1-exp(-lat_mat(ss,tt)/500);
    end
%     cost_mat(ss,:) = sgolayfilt(cost_mat(ss,:),3,11);
end

% for tt=1:numel(trans_vec)
%     cost_mat(:,tt) = sgolayfilt(cost_mat(:,tt),3,11);
% end

trans_axis = [ones(1,1)*react_sm(1) react_sm']-100;
sust_axis = sust_vec*6;
% sust_axis = sust_axis-min(sust_axis);

x = reshape(sust_axis'*ones(size(trans_axis)),numel(cost_mat),1);
y = reshape(ones(size(sust_axis))'*trans_axis,numel(cost_mat),1);
z = reshape(cost_mat,numel(cost_mat),1);

cost_surf_sims = fit([x y],z,'poly33');

figure(100); clf;

set(0,'DefaultFigureRenderer','painters');
s = surf(sust_axis,trans_axis,cost_mat'); hold on;
s = plot(cost_surf_sims);

s.EdgeColor = [0.35 0.35 0.35];
s.FaceAlpha = 0.85;
s.FaceLighting = 'gouraud';
colormap(s_map);
xlabel('Anticipatory');
ylabel('Reactive');
zlabel('Cost');
% axis([0 3 0 275 0 1.2]);
view(48,30);
% set(gca,'YDir','reverse');
set(gca,'Color',[0.95 0.95 0.95]);
box on; 

%% 1. Plot Cost vs Ant vs React for all Cntrl model sims
cmap = TNC_CreateRBColormap(6,'gp');
cmap2 = repmat(cmap(1:6,:),3,1);
fOff = 10 % for when rand wIn init is used
figure(1+fOff); clf;
figure(2); clf;

scnt = 1;

for g=1:numel(run)
% for g=13

    if stim_list(g)==0 % Only use Cntrl simulations

        cnt = 1;
        for gg=[1 run(g).net.update:run(g).net.update:numel(run(g).output.pass)] % Just examine the probed trials

            tmp_lat = find(run(g).output.pass(gg).chk.v > 1600,1,'first');
            if numel(tmp_lat)==1
                summary_data.analysis(1).lat(scnt,cnt) = run(g).output.pass(gg).chk.v(tmp_lat)-1600;
            else
                summary_data.analysis(1).lat(scnt,cnt) = 1400;
            end
            summary_data.analysis(1).cost(scnt,cnt) = 1-exp(-summary_data.analysis(1).lat(scnt,cnt)/500);
            summary_data.analysis(1).rct(scnt,cnt) = react_model(run(g).output.pass(gg).chk.npi(1605))+50;
            summary_data.analysis(1).ant(scnt,cnt) = numel(find(unique(run(g).output.pass(gg).chk.v)>600 & unique(run(g).output.pass(gg).chk.v)<1600));

            label_txt{scnt} = [num2str(inits(g)) '-' num2str(tau_vec(g),2) '-' num2str(wIn_vec(g),1)];

            cnt = cnt+1;

        end

% METHOD FOR COMPUTING LEARNING TRAJECTORIES
        summary_data.analysis(1).ant(scnt,:) = sgolayfilt(summary_data.analysis(1).ant(scnt,:),3,11);
        trial_rng = 120:160; % (i.e. 600 - 800)
        % Compute offset for fitting exponential
        trans_off = median(summary_data.analysis(1).rct(scnt,trial_rng));
        sust_off = median(summary_data.analysis(1).ant(scnt,trial_rng));
        lat_off = median(summary_data.analysis(1).lat(scnt,trial_rng));
        
        % Fit an exponential to the data
        trial_rng = 1:161;
        sustained_model = fit( trial_rng' , summary_data.analysis(1).ant(scnt,:)'-sust_off,'exp2','Lower',[-8 -0.1 -8 -0.1],'Upper',[5 0.1 5 0.1]);    
        transient_model = fit( trial_rng' , summary_data.analysis(1).rct(scnt,:)'-trans_off,'exp2','Lower',[50 -0.05 50 -0.5],'Upper',[500 0 500 0]);
        latency_model = fit( trial_rng' , summary_data.analysis(1).lat(scnt,:)'-lat_off,'exp2','Lower',[-5 -0.05 -5 -0.5],'Upper',[1400 0 1400 0]);
        
        transient_sm = transient_model(trial_rng)+trans_off;
        sustained_sm = sustained_model(trial_rng)+sust_off;
        latency_sm = latency_model(trial_rng)+lat_off;
        
        figure(2);
        total_sims = sum(stim_list==0);
        subplot(total_sims,3,((scnt-1)*3)+1); plot(summary_data.analysis(1).rct(scnt,:)); hold on; plot(transient_sm,'linewidth',3); %axis([0 161 0 1400]);
        subplot(total_sims,3,((scnt-1)*3)+2); plot(summary_data.analysis(1).ant(scnt,:)); hold on; plot(sustained_sm,'linewidth',3); axis([0 161 0 8]);
        subplot(total_sims,3,((scnt-1)*3)+3); plot(summary_data.analysis(1).lat(scnt,:)); hold on; plot(latency_sm,'linewidth',3); axis([0 161 70 700]);
        
        
        figure(1+fOff);
        if scnt==1    
            set(0,'DefaultFigureRenderer','painters');
            s = plot(cost_surf_sims); hold on;
%             s = surf(sust_axis,trans_axis,cost_mat');  hold on;
            s.EdgeColor = [0.35 0.35 0.35];
            s.FaceAlpha = 0.85;
            s.FaceLighting = 'gouraud';
            colormap(s_map);
            xlabel('Anticipatory');
            ylabel('Reactive');
            zlabel('Cost');
            % axis([0 3 0 275 0 1.2]);
            view(48,30);
            % set(gca,'YDir','reverse');
            set(gca,'Color',[0.95 0.95 0.95]);
            box on; 
        end
        if scnt<19
            % plot3(sustained_sm,transient_sm,log(latency_sm),'-','linewidth',2,'color','k'); hold on;
            % plot3(sustained_sm,transient_sm,1-exp(-latency_sm/500),'-','linewidth',1.5,'color',cmap2(scnt,:)); hold on;
%             plot3(sustained_sm,transient_sm,cost_surf_sims(sustained_sm,transient_sm)+0.01,'w-','linewidth',1.5,'color',cmap2(scnt,:)); hold on;
            plot3(sustained_sm,transient_sm,cost_surf_sims(sustained_sm,transient_sm)+0.01,'w-','linewidth',1.5); hold on;
            box on; view(48,30);
            set(gca,'Color',[0.95 0.95 0.95]);
            grid on;
            ylabel('Reactive');
            xlabel('Anticipatory');
            zlabel('Cost');
            axis([-2 5.2 65 300 0 0.7]);
            drawnow;
        end


        scnt = scnt + 1;
    end

end
legend(label_txt);

% figure(); plot3(summary_data.analysis(1).lat(1,:),summary_data.analysis(1).ant(1,:),summary_data.analysis(1).cost(1,:));

%% 2. Cued-DA stim simulation experiments in ACTR-C
global pt_on;
pt_on = 1;

stim_list = [zeros(1,18) 20*ones(1,18)];
% inits = repmat(ii([141 159 100 110 104 55]),1,2);
inits = repmat(ii([141 191 178 110 166 130]),1,6);
wIn_vec = repmat([zeros(1,6) zeros(1,6) ones(1,6)*0.33],1,4);
tau_vec = repmat([ones(1,6) 1+rand(1,6) ones(1,6)],1,4);


clear run;
parfor g = 1:numel(stim_list)

    net_init = gens.dets(inits(g)).net % diverse initial states
                
%     net_init.wIn(net.oUind,:) = [0 0];
%     tau_trans = 1; % now controls wJ learning rate

    net_init.wIn(net.oUind,:) = [wIn_vec(g)*0.5 wIn_vec(g)];
    tau_trans = tau_vec(g); % now controls eta_wIn learning rate

    filt_scale = 50; % plant scale factor currently

    % stim scalar determines whether a control (0) or lick- (-1) or lick+ (1) perturbation experiments
    stim = stim_list(g);
    [output,net_out,pred_da_sense,pred_da_move,pred_da_move_u,pred_da_sense_u,pred_da_move_o,pred_da_sense_o] = dlRNN_train_cuedDAstim(net_init,input,input_omit,input_uncued,target,act_func_handle,learn_func_handle,transfer_func_handle,65,tau_trans,stim,filt_scale);

    run(g).output = output;
    run(g).net = net_out;
    run(g).pred_da_sense = pred_da_sense;
    run(g).pred_da_move = pred_da_move;
    run(g).pred_da_sense_u = pred_da_sense_u;
    run(g).pred_da_move_u = pred_da_move_u;
    run(g).pred_da_sense_o = pred_da_sense_o;
    run(g).pred_da_move_o = pred_da_move_o;
    disp(['Completed run: ' num2str(g)]);

end

save ~/'Dropbox (HHMI)'/cued-da-run run stim_list inits


%% 2.5 Plot figure panels for cued-DA predictions

[stim_map] = [1 0 0.67 ; 0 1 0.67 ; 0 0.67 1];
lk_kern = TNC_CreateGaussian(500,40,1000,1);
jrcamp_tau = 500;
t=1:3000;
kern = [zeros(1,3000) exp(-t/jrcamp_tau)];
kern=kern/trapz(kern);
s_scl = 2;
m_scl = 1;
cnt = 1;
sl_cnt = 1;

for g=1:numel(run)

    switch stim_list(g)
        case 0
            num_das = size(run(g).pred_da_move,1);
            for ggg=1:num_das
                summary_data.analysis(2).da.c(ggg,:,cnt) = conv( s_scl*run(g).pred_da_sense(ggg,:) + m_scl*run(g).pred_da_move(ggg,:) , kern , 'same');
            end
            cnt = cnt+1;

        case 20
            num_das = size(run(g).pred_da_move,1);        
            for ggg=1:num_das
                summary_data.analysis(2).da_sl.c(ggg,:,sl_cnt) = conv( s_scl*run(g).pred_da_sense(ggg,:) + m_scl*run(g).pred_da_move(ggg,:) , kern , 'same');
            end
            sl_cnt = sl_cnt+1;
            
    end

end

%% 3. RPE predictions

[stim_map] = [1 0 0.67 ; 0 1 0.67 ; 0 0.67 1];
lk_kern = TNC_CreateGaussian(500,40,1000,1);
jrcamp_tau = 500;
t=1:3000;
kern = [zeros(1,3000) exp(-t/jrcamp_tau)];
kern=kern/trapz(kern);
s_scl = 2;
m_scl = 1;
cnt = 1;
sl_cnt = 1;

for g=1:numel(run)

    if stim_list(g)==0
            num_das = size(run(g).pred_da_move,1);
            for ggg=1:num_das
                summary_data.analysis(3).da.c(ggg,:,cnt) = conv( s_scl*run(g).pred_da_sense(ggg,:) + m_scl*run(g).pred_da_move(ggg,:) , kern , 'same');
                summary_data.analysis(3).da.u(ggg,:,cnt) = conv( s_scl*run(g).pred_da_sense_u(ggg,:) + m_scl*run(g).pred_da_move_u(ggg,:) , kern , 'same');
                summary_data.analysis(3).da.o(ggg,:,cnt) = conv( s_scl*run(g).pred_da_sense_o(ggg,:) + m_scl*run(g).pred_da_move_o(ggg,:) , kern , 'same');
            end
            cnt = cnt+1;
    end

end

% Compute the cue response (averaged over 100 trial bins)
% Compute reward responses for cntrl, uncued, omit same 100 trial bins
% Show RPE traces

%% 4. Lick+ / Lick- predictions

%% 5. PE|lick+ and PE|lick- vs training trials

% load ~/'Dropbox (HHMI)'/matlab.mat
% load ~/'Dropbox (HHMI)'/run.mat

% Need to analyze these variables:
% net_run.pass(pass).pe   = R_curr(curr_cond)-R_bar(curr_cond);
% net_run.pass(pass).plck = numel(find(anticip_lck>1)) / 10;
% net_run.pass(pass).chk(curr_cond).npi = outputs + curr_input(2,:)*net_out.wIn(net.oUind,2)  + curr_input(1,:)*net_out.wIn(net.oUind,1);

pe_map = TNC_CreateRBColormap(1024,'gp');

scnt = 1;
for g=1:numel(run)

    if stim_list(g)==0 % Only use Cntrl simulations

        cnt = 1;
        for gg=[1 run(g).net.update:run(g).net.update:numel(run(g).output.pass)] % Just examine the probed trials

            summary_data.analysis(5).pe(scnt,cnt) = run(g).output.pass(gg).pe;
            summary_data.analysis(5).plck(scnt,cnt) = run(g).output.pass(gg).plck;
            summary_data.analysis(5).chk(1).npi(scnt,cnt) = run(g).output.pass(gg).chk(1).npi(1605);
            cnt = cnt+1;

        end
        
        scnt = scnt+1;
    end
    
end

figure(50); 
subplot(6,1,1);
imagesc(summary_data.analysis(5).pe,[-250 250]); colormap(pe_map);
subplot(6,1,2);
shadedErrorBar(1:size(summary_data.analysis(5).pe,2),mean(summary_data.analysis(5).pe),std(summary_data.analysis(5).pe)); axis([0 cnt -200 200]); box off;
subplot(6,1,3);
imagesc(summary_data.analysis(5).plck,[-1 1]); colormap(pe_map);
subplot(6,1,4);
shadedErrorBar(1:size(summary_data.analysis(5).plck,2),mean(summary_data.analysis(5).plck),std(summary_data.analysis(5).plck)./sqrt(size(summary_data.analysis(5).plck,1))); box off; axis([0 cnt 0 1]); 
subplot(6,1,5);
imagesc(summary_data.analysis(5).chk(1).npi,[-10 10]); colormap(pe_map);
subplot(6,1,6);
shadedErrorBar(1:size(summary_data.analysis(5).plck,2),mean(summary_data.analysis(5).chk(1).npi),std(summary_data.analysis(5).chk(1).npi)./sqrt(size(summary_data.analysis(5).chk(1).npi,1))); box off; axis([0 cnt 0 11]); 

figure(51);
summary_data.analysis(5).all_cntrl_plck = summary_data.analysis(5).plck(1:numel(summary_data.analysis(5).plck));
summary_data.analysis(5).all_cntrl_pe = summary_data.analysis(5).pe(1:numel(summary_data.analysis(5).plck));
cnt = 1;
for pp=unique(summary_data.analysis(5).all_cntrl_plck)
    summary_data.analysis(5).bin_cntrl_LKperPE.avg(cnt) = mean(summary_data.analysis(5).all_cntrl_pe(summary_data.analysis(5).all_cntrl_plck==pp));
    summary_data.analysis(5).bin_cntrl_LKperPE.std(cnt) = std(summary_data.analysis(5).all_cntrl_pe(summary_data.analysis(5).all_cntrl_plck==pp))./sqrt(sum(summary_data.analysis(5).all_cntrl_plck==pp));
    cnt = cnt+1;
end
shadedErrorBar(unique(summary_data.analysis(5).all_cntrl_plck),summary_data.analysis(5).bin_cntrl_LKperPE.avg,summary_data.analysis(5).bin_cntrl_LKperPE.std); axis([0 1 -120 0]); box off;
ylabel('Mean PE'); xlabel('Prob(Lick+)');

%% 6. DA and Licking predictions for stimLick-, stimLick+, Stim++Lick+

[stim_map] = [1 0 0.67 ; 0 1 0.67 ; 0 0.67 1];
lk_kern = TNC_CreateGaussian(500,40,1000,1);
learn_ranges = [1 40 120; 20 60 160];
learn_ranges_da = [1 61; 60 120];

jrcamp_tau = 500;
t=1:3000;
kern = [zeros(1,3000) exp(-t/jrcamp_tau)];
kern=kern/trapz(kern);
s_scl = 2;
m_scl = 1;
cnt = 1;

% close all;

for g=[1 13 25 37]
% for g=[1 7]+1

    switch stim_list(g)
        case -1
            figure('Name',['Init ' num2str(inits(g)) ' : StimLick-' ],'NumberTitle','off'); clf;
        case 0
            figure('Name',['Init ' num2str(inits(g)) ' : Cntrl' ],'NumberTitle','off'); clf;
        case 1
            figure('Name',['Init ' num2str(inits(g)) ' : StimLick+' ],'NumberTitle','off'); clf;
        case 20
            figure('Name',['Init ' num2str(inits(g)) ' : Stim++Lick+' ],'NumberTitle','off'); clf;
    end

    summary_data.cond(g) = stim_list(g);
    summary_data.init(g) = inits(g);
    summary_data.net(g).neti = gens.dets(inits(g)).net;
    
    % For each pass generate the continuous lick and dopamine traces
    summary_data.trials(g).tr = run(g).net.update:run(g).net.update:numel(run(g).output.pass);
    summary_data.lik(g).lk = zeros(numel(summary_data.trials(g).tr),size(run(g).output.cond.out,2));
    summary_data.lik(g).lks = zeros(numel(summary_data.trials(g).tr),size(run(g).output.cond.out,2));
    summary_data.lat(g).la = zeros(numel(summary_data.trials(g).tr),3);
    summary_data.lat(g).las = zeros(numel(summary_data.trials(g).tr),3);

%     for gg=1:numel(run(g).output.pass)
    cnt=1;
    for gg=[run(g).net.update:run(g).net.update:numel(run(g).output.pass)]
        summary_data.lat(g).la(cnt,:) = [run(g).output.pass(gg).lat run(g).output.pass(gg).lat_u run(g).output.pass(gg).lat_o];
        summary_data.lik(g).lk(cnt,unique(run(g).output.pass(gg).chk.v)) = 1;
        summary_data.lik(g).lks(cnt,:) = conv(summary_data.lik(g).lk(cnt,:),lk_kern,'same');

        summary_data.pe(g).pe(cnt) = run(g).output.pass(gg).pe;
        summary_data.plck(g).plck(cnt) = run(g).output.pass(gg).plck;

        cnt = cnt+1;
    end

    for h=1:3
%         summary_data.lat(g).las(:,h) = conv(summary_data.lat(g).la(:,h),[0 ones(1,50) 0]/50,'same');
        summary_data.lat(g).las(:,h) = sgolayfilt(summary_data.lat(g).la(:,h),3,11);
    end

    subplot(141); imagesc(summary_data.lik(g).lks); colormap(bone); ylabel('Trials');
    subplot(142); plot(summary_data.trials(g).tr,summary_data.lat(g).las(:,1),'color',stim_map(3,:)); hold on;
    axis([0 800 0 750]);
    plot(summary_data.trials(g).tr,summary_data.lat(g).las(:,2),'color',stim_map(1,:));  
    ylabel('Latency');  xlabel('Trials');
    for h=1:3
        subplot(143); plot(1000*mean(summary_data.lik(g).lks(learn_ranges(1,h):learn_ranges(2,h),:)),'color',stim_map(h,:)); hold on;
    end
    axis([0 3000 -1 7]);
    ylabel('Lick rate (Hz)');  legend({'early' 'mid' 'late'},'location','northwest'); xlabel('Time');


    num_das = size(run(g).pred_da_move,1);
    summary_data.da(g).c = zeros(num_das,size(run(g).output.cond.out,2));
    summary_data.da(g).u = zeros(num_das,size(run(g).output.cond.out,2));
    summary_data.da(g).o = zeros(num_das,size(run(g).output.cond.out,2));

    for ggg=1:num_das
        summary_data.da(g).c(ggg,:) = conv( s_scl*run(g).pred_da_sense(ggg,:) + m_scl*run(g).pred_da_move(ggg,:) , kern , 'same');
    end

    for h=1:size(learn_ranges_da,2)
        subplot(144); plot(1000*mean(summary_data.da(g).c(learn_ranges_da(1,h):learn_ranges_da(2,h),:)),'color',stim_map(h,:)); hold on;
    end
    axis([0 3000 -1 20]);
    ylabel('DA resp. (a.u.)');  xlabel('Time'); legend({'1-300' '300-600'},'location','northwest');

end
%%
figure(31); clf;
subplot(2,4,[1:3 5:7]);
range = 20:20:140;
tc_sl = trapz(summary_data.analysis(2).da_sl.c,2);
plot([0 max(range)*5],[0 0],'k--'); hold on;
plot(range*5,mean(tc_sl(range,:,:),3),'o-','linewidth',2,'color',[0 0.67 1],'MarkerFaceColor','w'); hold on;
tc = trapz(summary_data.analysis(2).da.c,2);
plot(range*5,mean(tc(range,:,:),3),'ko-','linewidth',2,'MarkerFaceColor','w'); hold on;
% shadedErrorBar(range*5,mean(tc(range,:,:),3),std(tc(range,:,:),[],3)); hold on;
xlabel('Trials'); ylabel('Integrated cue response ACTR simulation (a.u.)');
box off;
axis([90 10+max(range)*5 -1 6]);

mean_range = 120:121;
tmp_sl = mean(summary_data.analysis(2).da_sl.c(mean_range,:,:),3);
tmp = mean(   summary_data.analysis(2).da.c(mean_range,:,:),3);
subplot(2,4,4);
shadedErrorBar(-1600:1399,mean(tmp_sl,1),std(tmp_sl,[],1)); hold on; axis([-1700 1500 -0.001 0.011]);
box off;

subplot(2,4,8);
shadedErrorBar(-1600:1399,mean(tmp,1),std(tmp,[],1)); hold on; axis([-1700 1500 -0.001 0.011]);
box off; xlabel('Time from stim (ms)'); ylabel('ACTR simulated DA response (a.u.)');

%% Summary display plot for talks of training experience.

% To plot:

% Trialwise / sessionwise:
% Anticipatory licking
% Fraction lick+ trials
%     per trial lick analysis is here:
%     run(1).output.pass(1).chk.v
% Performance errors on lick+ / lick- trials (maybe seeing the sign effect
% that stimLick exploits?)

% cued vs uncued latency
%     run(1).output.pass(1).lat
%     run(1).output.pass(1).lat_u
%     run(1).output.pass(1).lat_o






%% Analysis of performance over learning
% performance error on lick- vs lick+ trials over learning



%% Comparison across distinct run types
stim_cat = unique(stim_list);
stim_labels = { 'Lick-','Control','Lick+','Stim++Lick+' };
figure(601); clf;
            
    for sg = 1:numel(stim_cat)
        inds = find(stim_list==stim_cat(sg));
        plot(0:5:800,sgolayfilt(mean(model_runs.anticip(inds,:)),3,7),'color',stim_map(sg,:),'linewidth',2); hold on;
    end
    legend(stim_labels(1:numel(stim_cat)));

    ylabel('Anticipatory licks'); xlabel('Training trials'); 
    all_latency = zeros(numel(run) , 200); 
    all_latency_u = zeros(numel(run) , 200); 
    
    for kk=1:numel(run)
        all_latency(kk,1:numel(model(kk).latency)) = model(kk).latency(1,1:numel(model(kk).latency));
        all_latency_u(kk,1:numel(model(kk).latency_u)) = model(kk).latency_u(1,1:numel(model(kk).latency_u));
    end
    box off;

figure(602); clf;
    shadedErrorBar( [1:200]*run(1).net.update  , mean(all_latency,1) , std(all_latency,[],1)./sqrt(size(all_latency,1)) , {'color',[1 0.1 0.2]}); hold on;
    shadedErrorBar( [1:200]*run(1).net.update , mean(all_latency_u,1) , std(all_latency_u,[],1)./sqrt(size(all_latency_u,1)) ); hold on;
    ylabel('Latency to collect reward (ms)'); xlabel('Training trial bins');
    axis([0 200 0 500]);
